{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# I had been practicing with the model making and parallely use in other notebooks and in jupiter.\n",
        "# It works fine in both of them and in this model i achive a train accuracy of 99.6 and the test accuray of 98.5.\n",
        "# However i have tried it on other random dataset and it works fine on that\n",
        "# with this i think im now able to perform complex task with this model."
      ],
      "metadata": {
        "id": "LiHDLpIMxKjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UtCxLSJPXs2"
      },
      "outputs": [],
      "source": [
        "# import minist dataset and the nesessory frameworks\n",
        "import tensorflow_datasets as tfs\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization,Activation\n",
        "#  import pipeline fom sk.learn\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train,valid,test=tfs.load(\"mnist\",split=[\"train[:90%]\",\"train[90%:]\",\"test\"],as_supervised=True)"
      ],
      "metadata": {
        "id": "fXB09U9oPonV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline=Pipeline([\n",
        "    (\"scaler\",StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "A6Darr9yUPqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=train.shuffle(buffer_size=10000).batch(32).prefetch(1)\n",
        "valid=valid.batch(32).cache()\n",
        "test=test.batch(32).cache()"
      ],
      "metadata": {
        "id": "hBF24hwzRuGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential([\n",
        "    Flatten(input_shape=[28,28,1]),\n",
        "    Dense(300,kernel_initializer=\"he_normal\"),\n",
        "    BatchNormalization(),\n",
        "    Activation(\"relu\"),\n",
        "    Dense(300,kernel_initializer=\"he_normal\"),\n",
        "    BatchNormalization(),\n",
        "    Activation(\"relu\"),\n",
        "    Dense(300,kernel_initializer=\"he_normal\"),\n",
        "    BatchNormalization(),\n",
        "    Activation(\"relu\"),\n",
        "    Dense(300,kernel_initializer=\"he_normal\"),\n",
        "    BatchNormalization(),\n",
        "    Activation(\"relu\"),\n",
        "    Dense(10,activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n6-HfqpRuB5",
        "outputId": "97395665-f57d-4db7-8367-9597729c9368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "0FUSfDCSRt_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train,epochs=30,validation_data=valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abb1A0TVRt8v",
        "outputId": "8f20bcb4-a91a-46b6-bd45-70ed28ac5b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8911 - loss: 0.3515 - val_accuracy: 0.9660 - val_loss: 0.1089\n",
            "Epoch 2/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1223 - val_accuracy: 0.9660 - val_loss: 0.1212\n",
            "Epoch 3/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.0952 - val_accuracy: 0.9715 - val_loss: 0.0949\n",
            "Epoch 4/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0798 - val_accuracy: 0.9758 - val_loss: 0.0758\n",
            "Epoch 5/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0651 - val_accuracy: 0.9777 - val_loss: 0.0754\n",
            "Epoch 6/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0533 - val_accuracy: 0.9773 - val_loss: 0.0823\n",
            "Epoch 7/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0459 - val_accuracy: 0.9765 - val_loss: 0.0806\n",
            "Epoch 8/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0450 - val_accuracy: 0.9815 - val_loss: 0.0653\n",
            "Epoch 9/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0374 - val_accuracy: 0.9803 - val_loss: 0.0772\n",
            "Epoch 10/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0387 - val_accuracy: 0.9788 - val_loss: 0.0777\n",
            "Epoch 11/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0344 - val_accuracy: 0.9815 - val_loss: 0.0679\n",
            "Epoch 12/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0279 - val_accuracy: 0.9828 - val_loss: 0.0669\n",
            "Epoch 13/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0282 - val_accuracy: 0.9798 - val_loss: 0.0730\n",
            "Epoch 14/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0231 - val_accuracy: 0.9837 - val_loss: 0.0669\n",
            "Epoch 15/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.9812 - val_loss: 0.0774\n",
            "Epoch 16/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0258 - val_accuracy: 0.9837 - val_loss: 0.0675\n",
            "Epoch 17/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0222 - val_accuracy: 0.9807 - val_loss: 0.0832\n",
            "Epoch 18/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0192 - val_accuracy: 0.9813 - val_loss: 0.0840\n",
            "Epoch 19/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0205 - val_accuracy: 0.9820 - val_loss: 0.0700\n",
            "Epoch 20/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0195 - val_accuracy: 0.9853 - val_loss: 0.0646\n",
            "Epoch 21/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0180 - val_accuracy: 0.9850 - val_loss: 0.0688\n",
            "Epoch 22/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0132 - val_accuracy: 0.9808 - val_loss: 0.0863\n",
            "Epoch 23/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0149 - val_accuracy: 0.9838 - val_loss: 0.0721\n",
            "Epoch 24/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0144 - val_accuracy: 0.9852 - val_loss: 0.0746\n",
            "Epoch 25/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.9837 - val_loss: 0.0797\n",
            "Epoch 26/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0128 - val_accuracy: 0.9845 - val_loss: 0.0730\n",
            "Epoch 27/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0135 - val_accuracy: 0.9832 - val_loss: 0.0785\n",
            "Epoch 28/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0166 - val_accuracy: 0.9850 - val_loss: 0.0620\n",
            "Epoch 29/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0137 - val_accuracy: 0.9843 - val_loss: 0.0754\n",
            "Epoch 30/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.9852 - val_loss: 0.0723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(test)"
      ],
      "metadata": {
        "id": "LHCU7c30S92Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c560057b-a215-4ef8-e00f-889ae60b56a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABDoIvUzXGqb",
        "outputId": "17805eb0-1434-48ca-dae5-eaa118257710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9847000241279602"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "6RrYVyueYv2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mnist_model_001.h5\",save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swCmp8ZmXvHH",
        "outputId": "973bff87-3dcd-481b-b997-ee55e797a834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=tf\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ChXao67qX8cV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}